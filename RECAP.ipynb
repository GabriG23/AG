{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install 'torch>=1.8.2'\n",
    "!pip3 install 'torchvision>=0.9.2'\n",
    "!pip3 install 'faiss_cpu>=1.7.1'\n",
    "!pip3 install 'numpy>=1.21.2'\n",
    "!pip3 install 'Pillow>=9.0.1'\n",
    "!pip3 install 'scikit_learn>=1.0.2'\n",
    "!pip3 install 'tqdm>=4.62.3'\n",
    "!pip3 install 'utm>=0.7.0'\n",
    "\n",
    "import torch\n",
    "#use GPU if available \n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #'cpu' # 'cuda' or 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "- https://drive.google.com/file/d/1CQrhB_x9MECtjm0LjasXDxM9N9h24mnz/view?usp=share_link sf-xs.zip\n",
    "- https://drive.google.com/file/d/1FYcZuawvy42-PTyBl3PI8tKa1cLg__jN/view?usp=share_link tokyo-xs.zip\n",
    "- https://drive.google.com/file/d/14SVWnMgI9-jguNZPwUR1WcNXouADRCMz/view?usp=share_link tokyo-night.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown       # support for download a large file from Google Drive\n",
    "from google.colab import drive\n",
    "import os, sys\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# id = 1CQrhB_x9MECtjm0LjasXDxM9N9h24mnz sf-xs train, test e validation\n",
    "# id = 1FYcZuawvy42-PTyBl3PI8tKa1cLg__jN tokyo-xs solo test\n",
    "# id = 14SVWnMgI9-jguNZPwUR1WcNXouADRCMz tokyo-night solo test\n",
    "\n",
    "if not os.path.isfile('/content/sf-xs.zip'):\n",
    "  !gdown 1CQrhB_x9MECtjm0LjasXDxM9N9h24mnz # 3-5 min (sf-xs)\n",
    "  !jar xvf  \"/content/sf-xs.zip\"            # estrae il file zip nella cartella (in questo caso small)\n",
    "\n",
    "if not os.path.isdir('/content/sf-xs'):\n",
    "  print(\"Dataset doesn't exist\")\n",
    "\n",
    "if not os.path.isfile('/content/tokyo-xs.zip'):\n",
    "  !gdown 1FYcZuawvy42-PTyBl3PI8tKa1cLg__jN # 3-5 min (tokyo-xs)\n",
    "  !jar xvf  \"/content/tokyo-xs.zip\"            # estrae il file zip nella cartella (in questo caso small)\n",
    "\n",
    "if not os.path.isdir('/content/tokyo-xs'):\n",
    "  print(\"Dataset doesn't exist\")\n",
    "\n",
    "if not os.path.isfile('/content/tokyo-night.zip'):\n",
    "  !gdown 14SVWnMgI9-jguNZPwUR1WcNXouADRCMz # 3-5 min (tokyo-night)\n",
    "  !jar xvf  \"/content/tokyo-night.zip\"            # estrae il file zip nella cartella (in questo caso small)\n",
    "\n",
    "if not os.path.isdir('/content/tokyo-night'):\n",
    "  print(\"Dataset doesn't exist\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone \"https://github.com/GabriG23/AGP.git\" # usiamo il nostro, non possiamo fare modifiche sull'altro"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/content/AGP/\")\n",
    "import AGP\n",
    "from AGP import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiments\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on sf-xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 CosPlace/train.py --dataset_folder small --groups_num 1 --epochs_num 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-01-03 15:43:55   CosPlace/train.py --dataset_folder small --groups_num 1 --epochs_num 3\n",
    "# 2023-01-03 15:43:55   Arguments: Namespace(L=2, M=10, N=5, alpha=30, augmentation_device='cuda', backbone='resnet18', batch_size=32, brightness=0.7, classifiers_lr=0.01, contrast=0.7, dataset_folder='small', device='cuda', epochs_num=3, fc_output_dim=512, groups_num=1, hue=0.5, infer_batch_size=16, iterations_per_epoch=10000, lr=1e-05, min_images_per_class=10, num_workers=8, positive_dist_threshold=25, random_resized_crop=0.5, resume_model=None, resume_train=None, saturation=0.7, save_dir='default', seed=0, test_set_folder='small/test', train_set_folder='small/train', use_amp16=False, val_set_folder='small/val')\n",
    "# 2023-01-03 15:43:55   The outputs are being saved in logs/default/2023-01-03_15-43-55\n",
    "# /usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
    "#   warnings.warn(\n",
    "# /usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
    "#   warnings.warn(msg)\n",
    "# Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
    "# 100% 44.7M/44.7M [00:00<00:00, 257MB/s]\n",
    "# 2023-01-03 15:43:55   Train only layer3 and layer4 of the resnet18, freeze the previous ones\n",
    "# 2023-01-03 15:43:55   There are 1 GPUs and 2 CPUs.\n",
    "# 2023-01-03 15:44:00   Cached dataset cache/small_M10_N5_mipc10.torch does not exist, I'll create it now.\n",
    "# 2023-01-03 15:44:00   Searching training images in small/train\n",
    "# 2023-01-03 15:44:00   Found 59650 images\n",
    "# 2023-01-03 15:44:00   For each image, get its UTM east, UTM north and heading from its path\n",
    "# 2023-01-03 15:44:00   For each image, get class and group to which it belongs\n",
    "# 2023-01-03 15:44:00   Group together images belonging to the same class\n",
    "# 2023-01-03 15:44:00   Group together classes belonging to the same group\n",
    "# 2023-01-03 15:44:01   Using 1 groups\n",
    "# 2023-01-03 15:44:01   The 1 groups have respectively the following number of classes [5965]\n",
    "# 2023-01-03 15:44:01   The 1 groups have respectively the following number of images [59650]\n",
    "# 2023-01-03 15:44:01   Validation set: < val - #q: 7993; #db: 8015 >\n",
    "# 2023-01-03 15:44:01   Test set: < test - #q: 1000; #db: 27191 >\n",
    "# 2023-01-03 15:44:01   Start training ...\n",
    "# 2023-01-03 15:44:01   There are 5965 classes for the first group, each epoch has 10000 iterations with batch_size 32, therefore the model sees each class (on average) 53.6 times per epoch\n",
    "# /usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
    "#   warnings.warn(_create_warning_msg(\n",
    "# 100%|███████████████████████████████████████████████████████| 10000/10000 [1:12:50<00:00,  2.29it/s]\n",
    "# 2023-01-03 16:56:51   Epoch 00 in 1:12:50, loss = 7.9503\n",
    "# 2023-01-03 16:56:51   Extracting database descriptors for evaluation/testing\n",
    "# 100%|█████████████████████████████████████████████████████████████| 501/501 [01:07<00:00,  7.46it/s]\n",
    "# 2023-01-03 16:57:59   Extracting queries descriptors for evaluation/testing using batch size 1\n",
    "# 100%|███████████████████████████████████████████████████████████| 7993/7993 [01:50<00:00, 72.28it/s]\n",
    "# 2023-01-03 16:59:49   Calculating recalls\n",
    "# 2023-01-03 16:59:51   Epoch 00 in 1:15:49, < val - #q: 7993; #db: 8015 >: R@1: 78.7, R@5: 88.0\n",
    "# 100%|███████████████████████████████████████████████████████| 10000/10000 [1:12:52<00:00,  2.29it/s]\n",
    "# 2023-01-03 18:12:45   Epoch 01 in 1:12:53, loss = 3.3677\n",
    "# 2023-01-03 18:12:45   Extracting database descriptors for evaluation/testing\n",
    "# 100%|█████████████████████████████████████████████████████████████| 501/501 [01:04<00:00,  7.73it/s]\n",
    "# 2023-01-03 18:13:50   Extracting queries descriptors for evaluation/testing using batch size 1\n",
    "# 100%|███████████████████████████████████████████████████████████| 7993/7993 [01:48<00:00, 73.60it/s]\n",
    "# 2023-01-03 18:15:38   Calculating recalls\n",
    "# 2023-01-03 18:15:40   Epoch 01 in 1:15:48, < val - #q: 7993; #db: 8015 >: R@1: 81.8, R@5: 89.9\n",
    "# 100%|███████████████████████████████████████████████████████| 10000/10000 [1:12:50<00:00,  2.29it/s]\n",
    "# 2023-01-03 19:28:32   Epoch 02 in 1:12:51, loss = 2.4285\n",
    "# 2023-01-03 19:28:32   Extracting database descriptors for evaluation/testing\n",
    "# 100%|█████████████████████████████████████████████████████████████| 501/501 [01:05<00:00,  7.68it/s]\n",
    "# 2023-01-03 19:29:37   Extracting queries descriptors for evaluation/testing using batch size 1\n",
    "# 100%|███████████████████████████████████████████████████████████| 7993/7993 [01:50<00:00, 72.34it/s]\n",
    "# 2023-01-03 19:31:27   Calculating recalls\n",
    "# 2023-01-03 19:31:29   Epoch 02 in 1:15:48, < val - #q: 7993; #db: 8015 >: R@1: 83.2, R@5: 90.6\n",
    "# 2023-01-03 19:31:29   Trained for 03 epochs, in total in 3:47:34\n",
    "# 2023-01-03 19:31:30   Now testing on the test set: < test - #q: 1000; #db: 27191 >\n",
    "# 2023-01-03 19:31:30   Extracting database descriptors for evaluation/testing\n",
    "# 100%|███████████████████████████████████████████████████████████| 1700/1700 [03:43<00:00,  7.62it/s]\n",
    "# 2023-01-03 19:35:13   Extracting queries descriptors for evaluation/testing using batch size 1\n",
    "# 100%|███████████████████████████████████████████████████████████| 1000/1000 [00:16<00:00, 61.98it/s]\n",
    "# 2023-01-03 19:35:29   Calculating recalls\n",
    "# 2023-01-03 19:35:29   < test - #q: 1000; #db: 27191 >: R@1: 52.2, R@5: 66.3, R@10: 71.8, R@20: 76.3\n",
    "# 2023-01-03 19:35:29   Experiment finished (without any errors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving model & cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codice che scarica tutto, volendo lo si può anche salvare direttamente su file\n",
    "path1 = F\"/content/logs/default/2023-01-03_15-43-55/best_model.pth\" \n",
    "path2 = F\"/content/logs/default/2023-01-03_15-43-55/last_checkpoint.pth\"\n",
    "path3 = F\"/content/cache/small_M10_N5_mipc10.torch\"\n",
    "\n",
    "files.download(path1)\n",
    "files.download(path2)\n",
    "files.download(path3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on sf-xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non ho fatto in tempo ad eseguire i test\n",
    "# questo comando stava nel README\n",
    "!python3 eval.py --dataset_folder small/test --backbone resnet50 --fc_output_dim 128 --resume_model path/to/best_model.pth # il training model sta nella cartella cache03-01-23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on tokyo-xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 eval.py --dataset_folder tokyo_xs/test --backbone resnet50 --fc_output_dim 128 --resume_model path/to/best_model.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test on tokyo-night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 eval.py --dataset_folder tokyo-night/test --backbone resnet50 --fc_output_dim 128 --resume_model path/to/best_model.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Labels, plotting diagram, visualize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Ablation study (changing loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "659dd8b898eb39edfc3aaaab6aab2d48842c68bbbf5dfbec024edbbcce7543ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
